{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "# https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = pd.read_csv(\"../fresh_code/ultimate/train_test/df_train_summary.csv\")\n",
    "test_data = pd.read_csv(\"../fresh_code/ultimate/train_test/df_test_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 95)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to concatenate features, kfold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_concat(train_data1,filepath):\n",
    "    for file in filepath:\n",
    "        data_features = pd.read_csv(file)\n",
    "        data_features = data_features.drop_duplicates()\n",
    "        train_data1=pd.merge(train_data1,data_features,how='left',on='card_id')\n",
    "#         print(file)\n",
    "#         print(train_data1.shape)\n",
    "    return(train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_split(splitcount,train_data1,ignore_cols):  \n",
    "    output_feature=['target']\n",
    "    input_features=[x for x in train_data1.columns if x not in ignore_cols]\n",
    "    train_X = train_data1[input_features]\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    train_X = train_X.select_dtypes(include=numerics)\n",
    "    train_y = train_data1[output_feature]\n",
    "    kf = StratifiedKFold(n_splits=splitcount, random_state=2018, shuffle=True)\n",
    "    counter=0\n",
    "    models=[]\n",
    "    splits={}\n",
    "    for dev_index, val_index in kf.split(train_X,train_data1['target_bin']):\n",
    "        dev_X, val_X = train_X.loc[dev_index, :], train_X.loc[val_index, :]\n",
    "        dev_y, val_y = train_y.loc[dev_index], train_y.loc[val_index]\n",
    "        splits[counter] = [dev_X, val_X,dev_y, val_y]\n",
    "        counter=counter+1\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y):\n",
    "    param = {'num_leaves': 75,\n",
    "             'min_data_in_leaf': 200,\n",
    "             'objective': 'regression',\n",
    "             'max_depth': 14,\n",
    "             'learning_rate': 0.01,\n",
    "             \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.7,\n",
    "#              \"bagging_freq\": 1,\n",
    "#              \"bagging_fraction\": 0.7,\n",
    "#              \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.9,\n",
    "             \"random_state\": 133,\n",
    "             \"verbosity\": -1}\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(param, lgtrain, 10000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=1000,\n",
    "                      evals_result=evals_result)\n",
    "    \n",
    "    return model, evals_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../fresh_code/ultimate\\card_merc_count_pivot_svd.csv\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 3.69642\n",
      "[200]\tvalid_0's rmse: 3.6642\n",
      "[300]\tvalid_0's rmse: 3.65281\n",
      "[400]\tvalid_0's rmse: 3.6468\n",
      "[500]\tvalid_0's rmse: 3.64502\n",
      "Early stopping, best iteration is:\n",
      "[497]\tvalid_0's rmse: 3.6449\n",
      "{'best_iteration': 497, 'best_score': 3.6449034828182585, 'test_score': 3.4830274803554953, 'file_name': '../fresh_code/ultimate\\\\card_merc_count_pivot_svd.csv', 'split': 0}\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "file_list=glob.glob(\"../fresh_code/ultimate/*.csv\")\n",
    "model_results=[]\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    train_features1=feature_concat(train_data,[file])\n",
    "# Binning the numeric variable to different categories\n",
    "    target_std=train_features1['target'].std()\n",
    "    max_target=train_features1['target'].max()+1\n",
    "    min_target=train_features1['target'].min()-1\n",
    "    bins=[min_target,-3*target_std,-2*target_std,-1*target_std,target_std*1,target_std*2,target_std*3,max_target]\n",
    "    labels=[-4,-3,-2,0,2,3,5]\n",
    "    train_features1['target_bin']=pd.cut(train_features1['target'],bins=bins,labels=labels).astype(int)\n",
    "    train_features1['target_bin']=train_features1['target_bin'].abs()\n",
    "    train_features1.groupby(['target_bin']).size()\n",
    "    kfolds=kfold_split(5,train_features1,['Unnamed: 0','outliers','first_active_month', 'card_id','target','target_bin','year_nunique_y','year_nunique_x'])\n",
    "    \n",
    "    for split in range(0,5):\n",
    "        eval={}\n",
    "        X_train, X_test, y_train, y_test = train_test_split(kfolds[split][0],kfolds[split][2], test_size=0.1, random_state=42)\n",
    "        model, evals_result=run_lgb(X_train,y_train, kfolds[split][1], kfolds[split][3])\n",
    "        eval['best_iteration']=model.best_iteration\n",
    "        eval['best_score']=model.best_score['valid_0']['rmse']\n",
    "        pred=model.predict(X_test)\n",
    "        eval['test_score']=np.sqrt(mean_squared_error(y_test, pred))\n",
    "        eval['file_name']=file\n",
    "        eval['split']=split\n",
    "        model_results.append(eval)\n",
    "        print(eval)\n",
    "# train_features=train_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_iteration</th>\n",
       "      <th>best_score</th>\n",
       "      <th>file_name</th>\n",
       "      <th>split</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>497</td>\n",
       "      <td>3.644903</td>\n",
       "      <td>../fresh_code/ultimate\\card_merc_count_pivot_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.483027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_iteration  best_score  \\\n",
       "0             497    3.644903   \n",
       "\n",
       "                                           file_name  split  test_score  \n",
       "0  ../fresh_code/ultimate\\card_merc_count_pivot_s...      0    3.483027  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result=pd.DataFrame(model_results)\n",
    "model_result.to_csv(\"model_file_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
