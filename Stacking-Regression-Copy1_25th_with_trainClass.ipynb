{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestRegressor,  \n",
    "                               ExtraTreesRegressor)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv(\"C:/Kaggle competetion datasets/Elo Merchent Category Recommendation/Elo Feb 18th/ultimate2/ultimate2/train_test/train_features.csv\")\n",
    "df_test = pd.read_csv(\"C:/Kaggle competetion datasets/Elo Merchent Category Recommendation/Elo Feb 18th/ultimate2/ultimate2/train_test/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 86)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(123623, 84)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_concat(train_data1,filepath):\n",
    "    for file in filepath:\n",
    "        data_features = pd.read_csv(file)\n",
    "        data_features = data_features.drop_duplicates()\n",
    "        train_data1=pd.merge(train_data1,data_features,how='left',on='card_id')\n",
    "#         print(file)\n",
    "#         print(train_data1.shape)\n",
    "    return(train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py:187: DtypeWarning: Columns (1,9,17,28,37,44,55,64,70,78,87,94,104,113,119,131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  call = lambda f, *a, **k: f(*a, **k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import glob\n",
    "file_list = glob.glob(\"C:/Kaggle competetion datasets/Elo Merchent Category Recommendation/Elo Feb 18th/ultimate2/features_90/features_80/*.csv\")\n",
    "train_features=feature_concat(df_train,file_list)\n",
    "test_features=feature_concat(df_test,file_list)\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 534)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(123623, 532)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "target = df_train['target']\n",
    "train_features=train_features.fillna(0)\n",
    "test_features=test_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some useful parameters which will come in handy later on\n",
    "ntrain = train_features.shape[0]\n",
    "ntest = test_features.shape[0]\n",
    "SEED = 4590 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf, df_train, y_train, x_test,df_train_columns):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    val_metrics=[]\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        x_tr = df_train.iloc[trn_idx][df_train_columns]\n",
    "        y_tr = target.iloc[trn_idx]\n",
    "        x_va = df_train.iloc[val_idx][df_train_columns]\n",
    "        y_va = target.iloc[val_idx]\n",
    "        clf.train(x_tr, y_tr)\n",
    "        oof_train[val_idx] = clf.predict(x_va)\n",
    "        oof_test_skf[fold_, :] = clf.predict(x_test[df_train_columns])\n",
    "        val_metrics.append(np.sqrt(mean_squared_error(clf.predict(x_va), y_va)))\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1),val_metrics\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 60,\n",
    "    'min_samples_leaf': 177,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "lgb_param1 = {\n",
    "    'max_leaves':100,\n",
    "             'min_data_in_leaf': 177, \n",
    "             'max_depth': 60,\n",
    "            'feature_fraction':0.8,\n",
    "             'objective':'regression',\n",
    "             'learning_rate': 0.01,\n",
    "             \"boosting\": \"gbdt\",\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": 4,\n",
    "             \"random_state\": 4590}\n",
    "\n",
    "lgb_param2=lgb_param1.copy()\n",
    "lgb_param2['type']='gamma'\n",
    "\n",
    "lgb_param3=lgb_param1.copy()\n",
    "lgb_param3['type']='tweedie'\n",
    "\n",
    "\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 60,\n",
    "    'min_samples_leaf' : 177,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create object\n",
    "rf = SklearnHelper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "# ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "# gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "# svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "# xgbo = SklearnHelper(clf=xgb1, seed=SEED, params=svc_params)\n",
    "# lgbo = SklearnHelper(clf=lgb, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # important Features\n",
    "#step1:\n",
    "train_features = train_features.select_dtypes(include=numerics)\n",
    "train_features.columns = [x.replace(\"<lambda>\",\"range\") for x in train_features.columns]\n",
    "test_features.columns = [x.replace(\"<lambda>\",\"range\") for x in test_features.columns]\n",
    "df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','target','outliers','class_outcome']]\n",
    "\n",
    "# step2:\n",
    "# df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "\n",
    "\n",
    "# step3:\n",
    "#df_train_columns = imp_features1\n",
    "\n",
    "# step4:\n",
    "# df_train_columns=df_train_columns.extend('class_outcome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dd860b8c6a74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0met_oof_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0met_oof_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_metrics_et\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0met\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_train_columns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Extra Trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_metrics_et\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrf_oof_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_oof_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_metrics_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_train_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Random Forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_metrics_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ada_oof_train, ada_oof_test,val_metrics_ada = get_oof(ada, train_features, target, test_features,train_features_columns) # AdaBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c5bea2c0ea4c>\u001b[0m in \u001b[0;36mget_oof\u001b[1;34m(clf, df_train, y_train, x_test, df_train_columns)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0my_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moof_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_va\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moof_test_skf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-ed991fd61758>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 335\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "et_oof_train, et_oof_test,val_metrics_et = get_oof(et, train_features, target, test_features,df_train_columns) # Extra Trees\n",
    "print(val_metrics_et)\n",
    "rf_oof_train, rf_oof_test,val_metrics_rf = get_oof(rf, train_features, target, test_features,df_train_columns)# Random Forest\n",
    "print(val_metrics_rf)\n",
    "# ada_oof_train, ada_oof_test,val_metrics_ada = get_oof(ada, train_features, target, test_features,train_features_columns) # AdaBoost \n",
    "# gb_oof_train, gb_oof_test,val_metrics_gb = get_oof(gb, train_features, target, test_features,train_features_columns) # Gradient Boost\n",
    "# svc_oof_train, svc_oof_test,val_metrics_svc = get_oof(svc, train_features, target, test_features,df_train_columns) # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09952818773167374"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.09898099076058094, 0.0994351621675069, 0.09939453033492776, 0.09977368273143244, 0.10005657266392057])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Lightgbm\n",
    "def run_lgb1(df_train,df_test,df_train_columns,lgb_params):\n",
    "    param =  lgb_params\n",
    "    val_metrics=[]\n",
    "    oof_test_skf = np.empty((5, len(df_test)))\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "    oof_train = np.zeros(len(df_train))\n",
    "    oof_test = np.zeros(len(df_test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    print(df_train.shape)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "#         print(trn_data.shape,val_data.shape)\n",
    "        num_round = 3000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "        oof_train[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "#\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"Feature\"] = df_train_columns\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        \n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        test_predictions = clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration)\n",
    "        oof_test_skf[fold_, :] = test_predictions\n",
    "        \n",
    "        predictions= clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "        val_metrics.append(np.sqrt(mean_squared_error(predictions, target.iloc[val_idx])))\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return feature_importance_df,oof_train.reshape(-1,1),oof_test.reshape(-1,1),val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 377)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0986163\tvalid_1's rmse: 0.100066\n",
      "[200]\ttraining's rmse: 0.096277\tvalid_1's rmse: 0.0992515\n",
      "[300]\ttraining's rmse: 0.0945439\tvalid_1's rmse: 0.0990469\n",
      "[400]\ttraining's rmse: 0.0931198\tvalid_1's rmse: 0.0989835\n",
      "[500]\ttraining's rmse: 0.0919433\tvalid_1's rmse: 0.0990156\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's rmse: 0.0927349\tvalid_1's rmse: 0.098981\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0985026\tvalid_1's rmse: 0.100304\n",
      "[200]\ttraining's rmse: 0.0961795\tvalid_1's rmse: 0.0995641\n",
      "[300]\ttraining's rmse: 0.0944359\tvalid_1's rmse: 0.0994464\n",
      "[400]\ttraining's rmse: 0.0930167\tvalid_1's rmse: 0.0994472\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's rmse: 0.0936215\tvalid_1's rmse: 0.0994352\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0985629\tvalid_1's rmse: 0.100337\n",
      "[200]\ttraining's rmse: 0.0962694\tvalid_1's rmse: 0.0997042\n",
      "[300]\ttraining's rmse: 0.0945147\tvalid_1's rmse: 0.0994874\n",
      "[400]\ttraining's rmse: 0.0930926\tvalid_1's rmse: 0.0994021\n",
      "[500]\ttraining's rmse: 0.0919193\tvalid_1's rmse: 0.099399\n",
      "Early stopping, best iteration is:\n",
      "[480]\ttraining's rmse: 0.0921361\tvalid_1's rmse: 0.0993945\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0984439\tvalid_1's rmse: 0.100501\n",
      "[200]\ttraining's rmse: 0.0960372\tvalid_1's rmse: 0.0999555\n",
      "[300]\ttraining's rmse: 0.0942945\tvalid_1's rmse: 0.0998426\n",
      "[400]\ttraining's rmse: 0.0928326\tvalid_1's rmse: 0.099777\n",
      "[500]\ttraining's rmse: 0.0916923\tvalid_1's rmse: 0.0997836\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttraining's rmse: 0.0925371\tvalid_1's rmse: 0.0997737\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0983543\tvalid_1's rmse: 0.100556\n",
      "[200]\ttraining's rmse: 0.0959914\tvalid_1's rmse: 0.100113\n",
      "[300]\ttraining's rmse: 0.094223\tvalid_1's rmse: 0.100064\n",
      "[400]\ttraining's rmse: 0.0927891\tvalid_1's rmse: 0.100071\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's rmse: 0.0936482\tvalid_1's rmse: 0.100057\n",
      "[0.09898099076058094, 0.0994351621675069, 0.09939453033492776, 0.09977368273143244, 0.10005657266392057]\n"
     ]
    }
   ],
   "source": [
    "imp_features,lgb_oof_train, lgb_oof_test,val_metrics=run_lgb1(train_features,test_features,df_train_columns, lgb_param1)\n",
    "print(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imp_features1 = imp_features.groupby('Feature').agg({'importance':sum}).reset_index().sort_values(by = 'importance', ascending = False).head(250)['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate((et_oof_train, rf_oof_train,lgb_oof_train), axis=1)\n",
    "y_train = target\n",
    "x_test = np.concatenate((et_oof_test, rf_oof_test,lgb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Lightgbm\n",
    "def run_lgb2(df_train, df_test, lgb_params):\n",
    "   param =  lgb_params\n",
    "   val_metrics=[]\n",
    "   oof_test_skf = np.empty((5, len(df_test)))\n",
    "   folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "   oof_train = np.zeros(len(df_train))\n",
    "   oof_test = np.zeros(len(df_test))\n",
    "   #feature_importance_df = pd.DataFrame()\n",
    "   print(df_train.shape)\n",
    "   for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,target)):\n",
    "       print(\"fold {}\".format(fold_))\n",
    "       trn_data = lgb.Dataset(df_train.iloc[trn_idx], label=y_train.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "       val_data = lgb.Dataset(df_train.iloc[val_idx], label=y_train.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "#         print(trn_data.shape,val_data.shape)\n",
    "       num_round = 3000\n",
    "       clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "       oof_train[val_idx] = clf.predict(df_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "#\n",
    "#        fold_importance_df = pd.DataFrame()\n",
    "#        fold_importance_df[\"Feature\"] = df_train_columns\n",
    "       #fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "       \n",
    "       #fold_importance_df[\"fold\"] = fold_ + 1\n",
    "       #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "       test_predictions = clf.predict(df_test, num_iteration=clf.best_iteration)\n",
    "       oof_test_skf[fold_, :] = test_predictions\n",
    "       \n",
    "       predictions= clf.predict(df_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "       val_metrics.append(np.sqrt(mean_squared_error(predictions, y_train.iloc[val_idx])))\n",
    "   oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "   return oof_train.reshape(-1,1),oof_test.reshape(-1,1),val_metrics\n",
    "# stack_train=pd.DataFrame(x_train)\n",
    "# target=train_features['outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 3)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0999334\tvalid_1's rmse: 0.100048\n",
      "[200]\ttraining's rmse: 0.0991579\tvalid_1's rmse: 0.0994245\n",
      "[300]\ttraining's rmse: 0.0988866\tvalid_1's rmse: 0.0993505\n",
      "[400]\ttraining's rmse: 0.0987026\tvalid_1's rmse: 0.0994011\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's rmse: 0.0988866\tvalid_1's rmse: 0.0993505\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0998354\tvalid_1's rmse: 0.10026\n",
      "[200]\ttraining's rmse: 0.0990506\tvalid_1's rmse: 0.0997645\n",
      "[300]\ttraining's rmse: 0.0987885\tvalid_1's rmse: 0.0997438\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's rmse: 0.0988846\tvalid_1's rmse: 0.0997369\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0998456\tvalid_1's rmse: 0.100169\n",
      "[200]\ttraining's rmse: 0.099046\tvalid_1's rmse: 0.0996682\n",
      "[300]\ttraining's rmse: 0.0987672\tvalid_1's rmse: 0.0996521\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's rmse: 0.0988878\tvalid_1's rmse: 0.0996388\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.099776\tvalid_1's rmse: 0.100446\n",
      "[200]\ttraining's rmse: 0.0989771\tvalid_1's rmse: 0.100053\n",
      "[300]\ttraining's rmse: 0.098699\tvalid_1's rmse: 0.100101\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's rmse: 0.0989103\tvalid_1's rmse: 0.100046\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.0996771\tvalid_1's rmse: 0.100404\n",
      "[200]\ttraining's rmse: 0.09884\tvalid_1's rmse: 0.100182\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's rmse: 0.0989485\tvalid_1's rmse: 0.100173\n"
     ]
    }
   ],
   "source": [
    "stack_train=pd.DataFrame(x_train)\n",
    "target=train_features['outliers']\n",
    "lgb_oof_train, lgb_oof_test,val_metrics=run_lgb2(stack_train, pd.DataFrame(x_test), lgb_param1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09978908168569459"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission=pd.DataFrame(lgb_oof_test)\n",
    "submission['card_id']=test_features['card_id']\n",
    "submission.columns=['target','card_id']\n",
    "submission=submission[['card_id','target']]\n",
    "submission.to_csv(\"C:/Kaggle competetion datasets/Elo Merchent Category Recommendation/Elo Feb 18th/ultimate2/tf_combo2.csv\",index=False)\n",
    "# test_class.to_csv(\"../fresh_code/ultimate2/features/class/test_class.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_test = pd.DataFrame(x_test)\n",
    "stack_test['card_id'] = test_features['card_id']\n",
    "stack_test.to_csv(\"C:/Kaggle competetion datasets/Elo Merchent Category Recommendation/Elo Feb 18th/ultimate2/tfs_combo2.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
