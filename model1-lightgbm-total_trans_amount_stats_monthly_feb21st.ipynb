{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "# https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:\\\\Kaggle competetion datasets\\\\Elo Merchent Category Recommendation\\\\Elo Feb 18th\\\\summary_card\\\\df_train_summary.csv\")\n",
    "test_data = pd.read_csv(\"C:\\\\Kaggle competetion datasets\\\\Elo Merchent Category Recommendation\\\\Elo Feb 18th\\\\summary_card\\\\df_test_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 95)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(123623, 93)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to concatenate features, kfold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_concat(train_data1,filepath):\n",
    "    for file in filepath:\n",
    "        data_features = pd.read_csv(file)\n",
    "        train_data1=pd.merge(train_data1,data_features,how='left',on='card_id')\n",
    "    return(train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold_split(splitcount,train_data1,ignore_cols):  \n",
    "    output_feature=['target']\n",
    "    input_features=[x for x in train_data1.columns if x not in ignore_cols]\n",
    "    train_X = train_data1[input_features]\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    train_X = train_X.select_dtypes(include=numerics)\n",
    "    train_y = train_data1[output_feature]\n",
    "    kf = StratifiedKFold(n_splits=splitcount, random_state=2018, shuffle=True)\n",
    "    counter=0\n",
    "    models=[]\n",
    "    splits={}\n",
    "    for dev_index, val_index in kf.split(train_X,train_data1['target_bin']):\n",
    "        dev_X, val_X = train_X.loc[dev_index, :], train_X.loc[val_index, :]\n",
    "        dev_y, val_y = train_y.loc[dev_index], train_y.loc[val_index]\n",
    "        splits[counter] = [dev_X, val_X,dev_y, val_y]\n",
    "        counter=counter+1\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_list = glob.glob(\"C:/Kaggle competetion datasets/Elo Merchent Category Recommendation/Elo Feb 18th/total_trans_amount_stats_monthly_feb21st/*.csv\")\n",
    "train_features = feature_concat(train_data,file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 113)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_features=train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create correlation matrix\n",
    "# corr_matrix = train_features.corr().abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "\n",
    "# train_features=train_features1.drop(to_drop, axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_bin\n",
       "0    191093\n",
       "2      8200\n",
       "3       363\n",
       "4      2237\n",
       "5        24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binning the numeric variable to different categories\n",
    "target_std=train_features['target'].std()\n",
    "max_target=train_features['target'].max()+1\n",
    "min_target=train_features['target'].min()-1\n",
    "bins=[min_target,-3*target_std,-2*target_std,-1*target_std,target_std*1,target_std*2,target_std*3,max_target]\n",
    "labels=[-4,-3,-2,0,2,3,5]\n",
    "train_features['target_bin']=pd.cut(train_features['target'],bins=bins,labels=labels).astype(int)\n",
    "train_features['target_bin']=train_features['target_bin'].abs()\n",
    "train_features.groupby(['target_bin']).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kfolds = kfold_split(5,train_features,['first_active_month', 'card_id','target','target_bin','year_nunique_y','year_nunique_x', 'outliers', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y):\n",
    "    param = {'num_leaves': 30,\n",
    "             'min_data_in_leaf': 177,\n",
    "             'objective': 'regression',\n",
    "             'max_depth': 9,\n",
    "             'learning_rate': 0.01,\n",
    "             \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.7,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.7,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"random_state\": 133,\n",
    "             \"verbosity\": -1}\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(param, lgtrain, 2000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100,\n",
    "                      evals_result=evals_result)\n",
    "    return model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 3.69949\n",
      "[200]\tvalid_0's rmse: 3.66575\n",
      "[300]\tvalid_0's rmse: 3.65247\n",
      "[400]\tvalid_0's rmse: 3.64511\n",
      "[500]\tvalid_0's rmse: 3.64148\n",
      "[600]\tvalid_0's rmse: 3.63873\n",
      "[700]\tvalid_0's rmse: 3.63716\n",
      "[800]\tvalid_0's rmse: 3.63614\n",
      "[900]\tvalid_0's rmse: 3.6357\n",
      "[1000]\tvalid_0's rmse: 3.6358\n",
      "Early stopping, best iteration is:\n",
      "[957]\tvalid_0's rmse: 3.63557\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 3.72316\n",
      "[200]\tvalid_0's rmse: 3.69182\n",
      "[300]\tvalid_0's rmse: 3.6809\n",
      "[400]\tvalid_0's rmse: 3.67517\n",
      "[500]\tvalid_0's rmse: 3.67145\n",
      "[600]\tvalid_0's rmse: 3.66942\n",
      "[700]\tvalid_0's rmse: 3.6681\n",
      "[800]\tvalid_0's rmse: 3.66681\n",
      "[900]\tvalid_0's rmse: 3.66653\n",
      "[1000]\tvalid_0's rmse: 3.66649\n",
      "[1100]\tvalid_0's rmse: 3.6661\n",
      "[1200]\tvalid_0's rmse: 3.66598\n",
      "[1300]\tvalid_0's rmse: 3.66563\n",
      "[1400]\tvalid_0's rmse: 3.66531\n",
      "[1500]\tvalid_0's rmse: 3.66566\n",
      "Early stopping, best iteration is:\n",
      "[1414]\tvalid_0's rmse: 3.66513\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 3.704\n",
      "[200]\tvalid_0's rmse: 3.67064\n",
      "[300]\tvalid_0's rmse: 3.65863\n",
      "[400]\tvalid_0's rmse: 3.65219\n",
      "[500]\tvalid_0's rmse: 3.64909\n",
      "[600]\tvalid_0's rmse: 3.64613\n",
      "[700]\tvalid_0's rmse: 3.6446\n",
      "[800]\tvalid_0's rmse: 3.64359\n",
      "[900]\tvalid_0's rmse: 3.64232\n",
      "[1000]\tvalid_0's rmse: 3.64182\n",
      "[1100]\tvalid_0's rmse: 3.6413\n",
      "[1200]\tvalid_0's rmse: 3.64118\n",
      "[1300]\tvalid_0's rmse: 3.64103\n",
      "[1400]\tvalid_0's rmse: 3.6409\n",
      "[1500]\tvalid_0's rmse: 3.64081\n",
      "Early stopping, best iteration is:\n",
      "[1460]\tvalid_0's rmse: 3.64068\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 3.71932\n",
      "[200]\tvalid_0's rmse: 3.69187\n",
      "[300]\tvalid_0's rmse: 3.68264\n",
      "[400]\tvalid_0's rmse: 3.6776\n",
      "[500]\tvalid_0's rmse: 3.6749\n",
      "[600]\tvalid_0's rmse: 3.67338\n",
      "[700]\tvalid_0's rmse: 3.67267\n",
      "[800]\tvalid_0's rmse: 3.67245\n",
      "[900]\tvalid_0's rmse: 3.67207\n",
      "[1000]\tvalid_0's rmse: 3.67185\n",
      "[1100]\tvalid_0's rmse: 3.67135\n",
      "[1200]\tvalid_0's rmse: 3.67126\n",
      "[1300]\tvalid_0's rmse: 3.67119\n",
      "Early stopping, best iteration is:\n",
      "[1255]\tvalid_0's rmse: 3.6709\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's rmse: 3.70639\n",
      "[200]\tvalid_0's rmse: 3.67333\n",
      "[300]\tvalid_0's rmse: 3.6607\n",
      "[400]\tvalid_0's rmse: 3.65412\n",
      "[500]\tvalid_0's rmse: 3.65064\n",
      "[600]\tvalid_0's rmse: 3.64878\n",
      "[700]\tvalid_0's rmse: 3.64718\n",
      "[800]\tvalid_0's rmse: 3.6463\n",
      "[900]\tvalid_0's rmse: 3.64602\n",
      "[1000]\tvalid_0's rmse: 3.64515\n",
      "[1100]\tvalid_0's rmse: 3.64499\n",
      "Early stopping, best iteration is:\n",
      "[1098]\tvalid_0's rmse: 3.64495\n"
     ]
    }
   ],
   "source": [
    "best_list = []\n",
    "imp_list = []\n",
    "for split in range(0,5):\n",
    "    model, evals_result = run_lgb(kfolds[split][0], kfolds[split][2], kfolds[split][1], kfolds[split][3])\n",
    "    \n",
    "    best = {}\n",
    "    best['best_iter'] = model.best_iteration\n",
    "    best['best_score'] = model.best_score['valid_0']['rmse']\n",
    "    best_list.append(best)\n",
    "    feature_imp = pd.DataFrame(model.feature_importance(), kfolds[split][0].columns).sort_values(0,ascending=False).reset_index()\n",
    "    feature_imp['split'] = split\n",
    "    imp_list.append(feature_imp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'best_iter': 957, 'best_score': 3.6355685848696133},\n",
       " {'best_iter': 1414, 'best_score': 3.6651346835389984},\n",
       " {'best_iter': 1460, 'best_score': 3.640675120340088},\n",
       " {'best_iter': 1255, 'best_score': 3.670900513434806},\n",
       " {'best_iter': 1098, 'best_score': 3.6449481854727632}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>card_id_total</th>\n",
       "      <td>159.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_count_&lt;lambda&gt;</th>\n",
       "      <td>24.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_count_mean</th>\n",
       "      <td>316.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_count_var</th>\n",
       "      <td>328.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayofweek</th>\n",
       "      <td>128.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elapsed_time</th>\n",
       "      <td>281.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>241.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>122.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>61.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <td>1186.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <td>199.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_card_id_size</th>\n",
       "      <td>154.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_category_1_2_3_nunique</th>\n",
       "      <td>141.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <td>735.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <td>1043.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_category_2_mean_mean</th>\n",
       "      <td>301.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_category_3_mean_mean</th>\n",
       "      <td>465.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_city_id_nunique</th>\n",
       "      <td>127.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <td>29.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_dayofyear_nunique</th>\n",
       "      <td>268.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_first_buy</th>\n",
       "      <td>610.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_hour_nunique</th>\n",
       "      <td>187.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_max</th>\n",
       "      <td>81.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_mean</th>\n",
       "      <td>394.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_min</th>\n",
       "      <td>53.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_sum</th>\n",
       "      <td>540.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_var</th>\n",
       "      <td>373.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <td>230.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_merchant_id_nunique</th>\n",
       "      <td>404.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_month_diff_mean</th>\n",
       "      <td>1984.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_month_diff_mean</th>\n",
       "      <td>411.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_month_lag_max</th>\n",
       "      <td>50.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_month_lag_mean</th>\n",
       "      <td>749.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_month_lag_min</th>\n",
       "      <td>7.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_month_lag_var</th>\n",
       "      <td>279.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_month_nunique</th>\n",
       "      <td>14.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_amount_max</th>\n",
       "      <td>1186.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_amount_mean</th>\n",
       "      <td>694.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_amount_min</th>\n",
       "      <td>439.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_amount_sum</th>\n",
       "      <td>331.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_amount_var</th>\n",
       "      <td>555.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_date_average</th>\n",
       "      <td>605.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_date_diff</th>\n",
       "      <td>699.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_date_max</th>\n",
       "      <td>555.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_date_min</th>\n",
       "      <td>515.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_purchase_date_uptonow</th>\n",
       "      <td>1252.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_state_id_nunique</th>\n",
       "      <td>39.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_subsector_id_nunique</th>\n",
       "      <td>82.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_weekend_mean</th>\n",
       "      <td>132.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_weekend_sum</th>\n",
       "      <td>22.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_weekofyear_nunique</th>\n",
       "      <td>59.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_hist_year_nunique</th>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_amount_total</th>\n",
       "      <td>244.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_count_&lt;lambda&gt;</th>\n",
       "      <td>44.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_count_mean</th>\n",
       "      <td>204.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_count_var</th>\n",
       "      <td>298.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount_&lt;lambda&gt;</th>\n",
       "      <td>284.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount_mean</th>\n",
       "      <td>250.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_amount_var</th>\n",
       "      <td>270.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekofyear</th>\n",
       "      <td>245.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0  split\n",
       "index                                           \n",
       "card_id_total                       159.4      2\n",
       "city_count_<lambda>                  24.4      2\n",
       "city_count_mean                     316.4      2\n",
       "city_count_var                      328.2      2\n",
       "dayofweek                           128.6      2\n",
       "elapsed_time                        281.0      2\n",
       "feature_1                           241.4      2\n",
       "feature_2                           122.6      2\n",
       "feature_3                            61.8      2\n",
       "hist_authorized_flag_mean          1186.8      2\n",
       "hist_authorized_flag_sum            199.6      2\n",
       "hist_card_id_size                   154.4      2\n",
       "hist_category_1_2_3_nunique         141.8      2\n",
       "hist_category_1_mean                735.8      2\n",
       "hist_category_1_sum                1043.4      2\n",
       "hist_category_2_mean_mean           301.4      2\n",
       "hist_category_3_mean_mean           465.6      2\n",
       "hist_city_id_nunique                127.6      2\n",
       "hist_dayofweek_nunique               29.6      2\n",
       "hist_dayofyear_nunique              268.4      2\n",
       "hist_first_buy                      610.4      2\n",
       "hist_hour_nunique                   187.0      2\n",
       "hist_installments_max                81.2      2\n",
       "hist_installments_mean              394.6      2\n",
       "hist_installments_min                53.4      2\n",
       "hist_installments_sum               540.2      2\n",
       "hist_installments_var               373.2      2\n",
       "hist_merchant_category_id_nunique   230.6      2\n",
       "hist_merchant_id_nunique            404.6      2\n",
       "hist_month_diff_mean               1984.4      2\n",
       "...                                   ...    ...\n",
       "new_hist_month_diff_mean            411.4      2\n",
       "new_hist_month_lag_max               50.6      2\n",
       "new_hist_month_lag_mean             749.4      2\n",
       "new_hist_month_lag_min                7.8      2\n",
       "new_hist_month_lag_var              279.8      2\n",
       "new_hist_month_nunique               14.6      2\n",
       "new_hist_purchase_amount_max       1186.6      2\n",
       "new_hist_purchase_amount_mean       694.0      2\n",
       "new_hist_purchase_amount_min        439.6      2\n",
       "new_hist_purchase_amount_sum        331.8      2\n",
       "new_hist_purchase_amount_var        555.2      2\n",
       "new_hist_purchase_date_average      605.4      2\n",
       "new_hist_purchase_date_diff         699.6      2\n",
       "new_hist_purchase_date_max          555.8      2\n",
       "new_hist_purchase_date_min          515.6      2\n",
       "new_hist_purchase_date_uptonow     1252.6      2\n",
       "new_hist_state_id_nunique            39.2      2\n",
       "new_hist_subsector_id_nunique        82.4      2\n",
       "new_hist_weekend_mean               132.0      2\n",
       "new_hist_weekend_sum                 22.6      2\n",
       "new_hist_weekofyear_nunique          59.2      2\n",
       "new_hist_year_nunique                48.0      2\n",
       "purchase_amount_total               244.2      2\n",
       "sub_count_<lambda>                   44.0      2\n",
       "sub_count_mean                      204.4      2\n",
       "sub_count_var                       298.6      2\n",
       "total_amount_<lambda>               284.2      2\n",
       "total_amount_mean                   250.0      2\n",
       "total_amount_var                    270.8      2\n",
       "weekofyear                          245.6      2\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_list_df = pd.concat(imp_list, axis=0).groupby('index').agg('mean')\n",
    "imp_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline \n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(figsize=(12,10))\n",
    "# lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "# ax.grid(False)\n",
    "# plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Mean Feature_Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# fig, ax = plt.subplots(figsize=(12,20))\n",
    "# sns.barplot(x=\"Mean\", y=\"Col_Names\", data = feature_imp, orient='h',ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y):\n",
    "    param = {'num_leaves': 30,\n",
    "             'min_data_in_leaf': 177,\n",
    "             'objective': 'regression',\n",
    "             'max_depth': 9,\n",
    "             'learning_rate': 0.01,\n",
    "             \"boosting\": \"gbdt\",\n",
    "#              \"feature_fraction\": 0.7,\n",
    "             \"bagging_freq\": 1,\n",
    "             \"bagging_fraction\": 0.7,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'rmse',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"random_state\": 133,\n",
    "             \"verbosity\": -1}\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(param, lgtrain, 2000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100,\n",
    "                      evals_result=evals_result)\n",
    "    return model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
